# Just_Watch_Web_Scraping
Python Web Scraping project using Beautiful Soup

# Introduction

For this project, data about movies and TV series will be scraped from JustWatch, a popular website that gathers content from multiple streaming services. The scraping is done in Python using the queries module for HTTP requests and BeautifulSoup for HTML parsing. Instead of using JustWatch APIs, we extract data directly from the page's HTML structure.

# Website Link:

JustWatch - https://www.justwatch.com/in/movies_release_year_from=2000

# Project Workflow

1. **Web scraping**: Python apps employ BeautifulSoup, a package for parsing HTML structure. This process includes sending HTTP queries to the JustWatch website to retrieve relevant movie and TV show information. The application collects data by carefully going through the website's HTML and extracting titles, genres, release dates, and streaming platforms.

2. **Data Filtering and Analysis**: After scraping data, it can be processed and filtered using Numpy and Pandas, a powerful Python data processing program. After removing duplicates and inconsistencies, the data is cleaned in this step and arranged systematically. Pandas enables statistical analysis and the creation of content insights, including the recognition of patterns and trends, by facilitating thorough data exploration.

3. **Findings and Perspectives**: The data analysis with filters provides valuable insights into the films and television shows that are accessible on different streaming platforms. These observations may include identifying the most popular genres, the largest selections offered by streaming services, and other relevant information. Examining these advancements can help us understand the current situation of streaming content.

4. **Data Visualization**: To highlight important findings like the most popular streaming website, highest ratings, and most popular genres, visual representations of the data are made using tools like word clouds and bar charts. In order to produce lucid and captivating graphics that facilitate the interpretation of trends and patterns in the data, this stage makes use of libraries such as WordCloud Matplotlib or Seaborn.

5. **Data Export**: A CSV file with the analysis's final findings is stored after it is finished. Further analysis or visualization is made possible by this format, which guarantees that the data is organized and simple to share. A broader audience can access and use the insights by using the CSV file to generate charts, graphs, and reports using various tools and platforms.


**Technologies Used**

***Python***

***Requests library for HTTP requests***

***BeautifulSoup for HTML parsing***

***Numpy for framework***

***Pandas for data manipulation and analysis***

***WordCloud for word visualization***



